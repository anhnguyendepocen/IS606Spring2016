---
title: "IS606 - Intro to Bayesian Analysis"
author: Jason Bryer, Ph.D.
date: December 2, 2015
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
---
	
<div class="notes">
Documentation on using ioslides is available here:
http://rmarkdown.rstudio.com/ioslides_presentation_format.html
Some slides are adopted (or copied) from OpenIntro: https://www.openintro.org/
</div>

```{r setup, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
set.seed(2112)
library(ggplot2)
library(openintro)
library(IS606)
library(reshape2)
library(psych)
library(reshape2)
library(xtable)
options(width=100)
par(mar=c(2.5,1,2,1))

```

## Announcements

* Meetup schedule for the rest of the semester.
	* No meetup on December 10th.
	* Final meetup on December 17th!
* Focus on Chapters 2 and 5 from Kruschke on Bayesian Analysis.
* Final Exam will be available on December 14th, it is due by 5pm on December 17th (no late submissions will be accepted!)

## Meetup Presentations

* Michael Lennon (2.1)
* Frank de Olivera (5.3)
* Randi Skrelja (5.45)
* Cheryl Bowersox (5.45)
* Angus Huang (6.2)

* Andrew Goldberg (2.1): https://www.youtube.com/watch?v=gwpN_IYAmL0

## Bayesian Analysis


<img src='http://ecx.images-amazon.com/images/I/515eRFg9Y8L._SX404_BO1,204,203,200_.jpg' align='right'>

Kruschke's videos are an excelent introduction to Bayesian Analysis [https://www.youtube.com/watch?v=YyohWpjl6KU](https://www.youtube.com/watch?v=YyohWpjl6KU)!

[Doing Bayesian Data Analysis, Second Edition: A Tutorial with R, JAGS, and Stan](http://www.amazon.com/Doing-Bayesian-Data-Analysis-Second/dp/0124058884/ref=sr_1_1?ie=UTF8&qid=1437688316&sr=8-1&keywords=Kruschke)


## Bayes Theorem

$$ P\left( A|B \right) =\frac { P\left( B|A \right) P\left( A \right)  }{ P\left( B|A \right) P\left( A \right) +P\left( B|{ A }^{ ` } \right) P\left( { A }^{ ` } \right)  }   $$

Consider the following data from a cancer test:

* 1% of women have breast cancer (and therefore 99% do not).
* 80% of mammograms detect breast cancer when it is there (and therefore 20% miss it).
* 9.6% of mammograms detect breast cancer when it’s not there (and therefore 90.4% correctly return a negative result).

&nbsp;        | Cancer (1%) | No Cancer (99%)
--------------|-------------|-----------------
Test postive  | 80%         |  9.6%
Test negative | 20%         |  90.4%


## How accurate is the test?

Now suppose you get a positive test result. What are the chances you have cancer? 80%? 99%? 1%?

* Ok, we got a positive result. It means we’re somewhere in the top row of our table. Let’s not assume anything — it could be a true positive or a false positive.
* The chances of a true positive = chance you have cancer * chance test caught it = 1% * 80% = .008
* The chances of a false positive = chance you don’t have cancer * chance test caught it anyway = 99% * 9.6% = 0.09504

&nbsp;        | Cancer (1%)       | No Cancer (99%)
--------------|-------------------|-----------------
Test postive  | True +: 1% * 80%  | False +: 99% * 9.6%
Test negative | False -: 1% * 20% | True -: 99% * 90.4%

## How accurate is the test?

$$ Probability = \frac{desired\quad event}{all\quad possibilities} $$

The chance of getting a real, positive result is .008. The chance of getting any type of positive result is the chance of a true positive plus the chance of a false positive (.008 + 0.09504 = .10304).

**So, our chance of cancer is .008/.10304 = 0.0776, or about 7.8%.**

## Bayes Formula

It all comes down to the chance of a true positive result divided by the chance of any positive result. We can simplify the equation to:

$$ P\left( A|B \right) =\frac { P\left( B|A \right) P\left( A \right)  }{ P\left( B \right)  }  $$

## How many fish are in the lake?

* Catch them all, count them. Not practical (ore even possible)!
* We can sample some fish.

Our strategy:

1. Catch some fish.
2. Mark them.
3. Return the fish to the pond. Let them get mixed up (i.e. wait a while).
4. Catch some more fish.
5. Count how many are marked.

For example, we initially caught 20 fish, marked them, returned them to the pond. We then caught another 20 fish and 5 of them were marked (i.e they were caught the first time).

<font size='-2'>
Adopted from Rasmath Bååth useR! 2015 workshop: http://www.sumsar.net/files/academia/user_2015_tutorial_bayesian_data_analysis_short_version.pdf
</font>

## Strategy for fitting a model {.flexbox .vcenter}

Step 1: Define Prior Distribution. Draw a lot of random samples from the "prior" probability distribution on the parameters.

```{r, fig.width=8, fig.height=3}
n_draw <- 100000
n_fish <- sample(20:250, n_draw, replace = TRUE)
head(n_fish, n=10)
hist(n_fish, main="Prior Distribution")
```

## Strategy for fitting a model {.flexbox .vcenter}

Step 2: Plug in each draw into the generative model which generates "fake" data.

```{r}
pick_fish <- function(n_fish) { # The generative model
	fish <- rep(0:1, c(n_fish - 20, 20))
	sum(sample(fish, 20))
}
n_marked <- rep(NA, n_draw)
for(i in 1:n_draw) {
	n_marked[i] <- pick_fish(n_fish[i])
}
head(n_marked, n=10)
```

## Strategy for fitting a model {.flexbox .vcenter}

Step 3: Keep only those parameter values that generated the data that was actually observed (in this case, 5).

```{r, fig.width=8, fig.height=3}
post_fish <- n_fish[n_marked == 5]
hist(post_fish, main='Posterior Distribution')
abline(v=median(post_fish), col='red')
abline(v=quantile(post_fish, probs=c(.25, .75)), col='green')
```

## What if we have better prior information? {.flexbox .vcenter}

An "expert" believes there are around 200 fish in the pond. Insteand of a uniform distribution, we can use a binomial distribution to define our "prior" distribution.

```{r, fig.width=8, fig.height=3}
n_fish <- rnbinom(n_draw, mu = 200 - 20, size = 4) + 20
hist(n_fish, main='Prior Distribution')
```

## What if we have better prior information? {.flexbox .vcenter}

```{r, fig.width=8, fig.height=3}
n_marked <- rep(NA, n_draw)
for(i in 1:n_draw) {
	n_marked[i] <- pick_fish(n_fish[i])
}
post_fish <- n_fish[n_marked == 5]
hist(post_fish, main='Posterior Distribution')
abline(v=median(post_fish), col='red')
abline(v=quantile(post_fish, probs=c(.25, .75)), col='green')
```



